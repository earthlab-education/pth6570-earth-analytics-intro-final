{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"cced8803-3670-402b-8eb8-ae2b5f051d13\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"32c2671a-f203-47f8-bc64-6662d97e829a\":{\"version\":\"3.3.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"a790f4f7165543bba5a4852712eb0d87\",\"client_comm_id\":\"0dddd683a6e346e5864a9756a5de701b\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"toggle_value1\",\"properties\":[{\"name\":\"active_icons\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"options\",\"kind\":\"Any\",\"default\":{\"type\":\"map\",\"entries\":[[\"favorite\",\"heart\"]]}},{\"name\":\"value\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_reactions\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_base_url\",\"kind\":\"Any\",\"default\":\"https://tabler-icons.io/static/tabler-icons/icons/\"}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"value\",\"kind\":\"Any\",\"default\":null},{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"32c2671a-f203-47f8-bc64-6662d97e829a\",\"roots\":{\"p1002\":\"cced8803-3670-402b-8eb8-ae2b5f051d13\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import io\n",
    "import math \n",
    "import os\n",
    "# import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.appeears as etapp\n",
    "import earthpy.earthexplorer as etee\n",
    "import geopandas as gpd\n",
    "import hvplot.xarray  \n",
    "import hvplot.pandas\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "import requests\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "# from shapely.geometry import box\n",
    "from xrspatial import aspect\n",
    "from xrspatial import slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME, 'final_project')\n",
    "if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "# Make data directory the working directory\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Define utm zone\n",
    "utm = 32613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading shapefile...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from: https://medium.com/@loldja/reading-shapefile-zips-from-a-url-in-python-3-93ea8d727856\n",
    "# Create directory\n",
    "grassland_url = ('https://data.fs.usda.gov/geodata/edw/'\n",
    "                 'edw_resources/shp/S_USA.NationalGrassland.zip'\n",
    ")\n",
    "print('Downloading shapefile...')\n",
    "\n",
    "# Request data from url\n",
    "grassland_request = requests.get(grassland_url)\n",
    "grassland_zip = zipfile.ZipFile(io.BytesIO(grassland_request.content))\n",
    "\n",
    "# Extract files from zip and save to directory\n",
    "grassland_zip.extractall(\n",
    "    path=os.path.join(data_dir, 'national-grassland')\n",
    "    )\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile\n",
    "grassland_gdf = gpd.read_file(os.path.join(\n",
    "    data_dir, 'national-grassland', 'S_USA.NationalGrassland.shp')\n",
    "    )\n",
    "\n",
    "# Get selected grasslands\n",
    "select_grassland_gdf = (\n",
    "    grassland_gdf\n",
    "    .set_index('GRASSLANDN')\n",
    "    .loc[['Comanche National Grassland', 'Pawnee National Grassland']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Comanche National Grassland :\n",
      "mean_ph_lat3637_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat3637_lon-104-103.tif is already downloaded\n",
      "mean_ph_lat3637_lon-103-102.tif is already downloaded\n",
      "mean_ph_lat3738_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat3738_lon-104-103.tif is already downloaded\n",
      "mean_ph_lat3738_lon-103-102.tif is already downloaded\n",
      "A merged soil data array already exists.\n",
      "\n",
      " Pawnee National Grassland :\n",
      "mean_ph_lat4041_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat4041_lon-104-103.tif is already downloaded\n",
      "mean_ph_lat4142_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat4142_lon-104-103.tif is already downloaded\n",
      "A merged soil data array already exists.\n"
     ]
    }
   ],
   "source": [
    "def get_polaris_data(data_directory, input_gdf, index_col_name):\n",
    "    \"\"\"\n",
    "    This function downloads Polaris soil data for the extent of each \n",
    "    row in a geodataframe and creates a merged data array for each. \n",
    "    Downloaded data is saved in individual folders for each row. Merged \n",
    "    data arrays for each row are saved in \"Merged_files\" subfolder.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_directory : path\n",
    "        The path to the data directory. A sub-directory will be created\n",
    "        within this directory for the soil data downloads. \n",
    "\n",
    "    input_gdf: geopandas.GeoDataFrame\n",
    "        A geodataframe that contains the areas of interest. Polaris soil\n",
    "        data will be downloaded according to the bounds of each row in \n",
    "        the dataframe. \n",
    "    \n",
    "    index_col_name: string\n",
    "        A string containing the name of the geoDataFrame column that\n",
    "        should be used as the index. This index will be used to name\n",
    "        output files.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    output_lst: list of data arrays\n",
    "        Returns a list of data arrays representing the merged Polaris\n",
    "        tif data for each row in the input geodataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Set index to specified index column\n",
    "    input_gdf = input_gdf.reset_index().set_index(index_col_name)\n",
    "\n",
    "    # Create dataframe of bounds of each gdf row\n",
    "    bound_pd = pd.concat([input_gdf.bounds], axis=1)\n",
    "\n",
    "    file_list = []\n",
    "    \n",
    "    # Loop through each row in the boundary dataframe\n",
    "    for ind in bound_pd.index:\n",
    "        print(\"\\n\", ind, \":\")\n",
    "        # Define and round min and max longitude and latitudes\n",
    "        min_lon = math.floor(bound_pd['minx'][ind])\n",
    "        max_lon = math.ceil(bound_pd['maxx'][ind])\n",
    "        min_lat = math.floor(bound_pd['miny'][ind])\n",
    "        max_lat = math.ceil(bound_pd['maxy'][ind])\n",
    "        # Define range\n",
    "        lat_range = range(min_lat,max_lat)\n",
    "        lon_range = range(min_lon,max_lon)\n",
    "\n",
    "        # Create template for polaris url path\n",
    "        polaris_template_url = 'http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/' \\\n",
    "                    '{0}/{1}/{2}/lat{3}{4}_lon{5}{6}.tif'\n",
    "        # Create template for file names\n",
    "        polaris_template_name = 'mean_ph_lat{0}{1}_lon{2}{3}.tif'\n",
    "\n",
    "        # Create sub-directory for soil data\n",
    "        soil_dir = os.path.join(data_directory, \"soil_data\")\n",
    "        if not os.path.exists(soil_dir):\n",
    "            os.makedirs(soil_dir)\n",
    "\n",
    "        # Create sub-folders for each row's data\n",
    "        soil_row_dir = os.path.join(soil_dir, str(ind).replace(\" \", \"_\"))\n",
    "        if not os.path.exists(soil_row_dir):\n",
    "            os.makedirs(soil_row_dir)\n",
    "        \n",
    "        # Create sub-folder for merged data arrays\n",
    "        soil_merged_dir = os.path.join(soil_dir, \"Merged_tifs\")\n",
    "        if not os.path.exists(soil_merged_dir):\n",
    "            os.makedirs(soil_merged_dir)\n",
    "        \n",
    "        # For each latitude and longitude in the extent, download file\n",
    "        for lat in lat_range:\n",
    "            for lon in lon_range:\n",
    "                # Define url for each data file in extent\n",
    "                url = polaris_template_url.format('ph',\n",
    "                                        'mean',\n",
    "                                        '60_100',\n",
    "                                        str(lat),\n",
    "                                        str(lat+1),\n",
    "                                        str(lon),\n",
    "                                        str(lon+1))\n",
    "                # Define file name for each data file in extent\n",
    "                file_name = polaris_template_name.format(str(lat),\n",
    "                                        str(lat+1),\n",
    "                                        str(lon),\n",
    "                                        str(lon+1))\n",
    "                # Check if tif file is in directory. Download if not.\n",
    "                file_name_path = os.path.join(soil_row_dir, file_name)\n",
    "                if not os.path.exists(file_name_path): \n",
    "                    print(file_name, \"does not exist. Downloading file\")\n",
    "                    r = requests.get(url, allow_redirects=True)\n",
    "                    open(file_name_path, 'wb').write(r.content)\n",
    "                else:\n",
    "                    print(file_name, \"is already downloaded\")\n",
    "\n",
    "        # Merge arrays if the merged file does not exist\n",
    "        merge_template_name = '{0}_merged_da.tif'\n",
    "        merge_da_name = merge_template_name.format(str(ind).replace(\" \", \"_\"), \".tif\")\n",
    "        if not os.path.exists(os.path.join(soil_merged_dir, merge_da_name)): \n",
    "            print(\"Soil data is being merged.\")\n",
    "            tif_paths = glob(os.path.join(soil_row_dir, '*.tif'))\n",
    "            das = [rxr.open_rasterio(tif, masked=True) for tif in tif_paths]\n",
    "            merged_da = rxrmerge.merge_arrays(das)\n",
    "            merged_da.rio.to_raster(\n",
    "                os.path.join(soil_merged_dir, merge_da_name)\n",
    "                )\n",
    "            print(\"Merged soil file created.\")\n",
    "        else:\n",
    "            print(\"A merged soil data array already exists.\")\n",
    "            merged_da = rxr.open_rasterio(\n",
    "                os.path.join(soil_merged_dir, merge_da_name), masked=True\n",
    "                )\n",
    "        \n",
    "        # Add file to list of tif files to return\n",
    "        file_list.append(os.path.join(soil_merged_dir, merge_da_name))\n",
    "        \n",
    "    # Return files\n",
    "    output_lst = [rxr.open_rasterio(tif, masked=True).squeeze() for tif in file_list]\n",
    "    return output_lst\n",
    "\n",
    "comanche_pH_da, pawnee_pH_da = get_polaris_data(data_dir, select_grassland_gdf, \"GRASSLANDN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change projection of grassland data\n",
    "select_grassland_utm_gdf = select_grassland_gdf.to_crs(utm)\n",
    "\n",
    "# Clip pH files to bounds\n",
    "comanche_pH_da = (comanche_pH_da\n",
    "                  .rio.reproject(utm)\n",
    "                  .rio.clip_box(\n",
    "                      *select_grassland_utm_gdf\n",
    "                      .loc[['Comanche National Grassland']]\n",
    "                      .total_bounds)\n",
    ")\n",
    "pawnee_pH_da = (pawnee_pH_da\n",
    "                  .rio.reproject(utm)\n",
    "                  .rio.clip_box(\n",
    "                      *select_grassland_utm_gdf\n",
    "                      .loc[['Pawnee National Grassland']]\n",
    "                      .total_bounds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pawnee_ph_plt = (\n",
    "    pawnee_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\"\n",
    ")\n",
    "\n",
    "comanche_ph_plt = (\n",
    "    comanche_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change crs of selected grasslands\n",
    "select_grassland_gdf = select_grassland_gdf.to_crs(4326)\n",
    "\n",
    "# Download AppEEARS SRTM DEM data for full extent\n",
    "elevation_downloader = etapp.AppeearsDownloader(\n",
    "    download_key=\"SRTM_DEM\",\n",
    "    ea_dir=data_dir,\n",
    "    product=\"SRTMGL1_NC.003\",\n",
    "    layer=\"SRTMGL1_DEM\",\n",
    "    start_date=\"02-11\",\n",
    "    end_date=\"02-21\",\n",
    "    recurring=True,\n",
    "    year_range=[2000,2000],\n",
    "    polygon=select_grassland_gdf,\n",
    ")\n",
    "\n",
    "# Download files if the download directory does not exist\n",
    "if not os.path.exists(elevation_downloader.data_dir):\n",
    "    elevation_downloader.download_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read elevation data.\n",
    "for tif in glob(os.path.join(data_dir, 'SRTM_DEM',\n",
    "                'SRTMGL1_NC*',\n",
    "                '*.tif')):\n",
    "    elev_da = rxr.open_rasterio(tif, masked=True).squeeze()\n",
    "    elev_da.name = 'Elevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_and_reproj_match(in_da, clip_gdf, match_da):\n",
    "    \"\"\"\n",
    "    This function clips a data array to a specificed extent and \n",
    "    harmonizes the array to match another data array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_da: xarray.DataArray\n",
    "        Represents the data array that is to be clipped and reprojected\n",
    "\n",
    "    clip_gdf: geopandas.GeoDataFrame\n",
    "        The geodataframe to which the data input area should be clipped\n",
    "\n",
    "    match_da: xarray.DataArray\n",
    "        The data array for which the input data array should be \n",
    "        reprojected to match the resolution, projection, and region\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    clip_da: xarray.DataArray\n",
    "        A clipped and harmonized version of the input data array\n",
    "    \"\"\"\n",
    "    # Clip to extent of input and reproject match to specified array\n",
    "    clip_da = (in_da\n",
    "                  .rio.clip_box(*clip_gdf.to_crs(in_da.rio.crs)\n",
    "                                .total_bounds)\n",
    "                  .rio.reproject_match(match_da))\n",
    "    \n",
    "    return clip_da\n",
    "\n",
    "# Run function for Pawnee and Comanche\n",
    "pawnee_elev_da = clip_and_reproj_match(elev_da, select_grassland_gdf.loc[['Pawnee National Grassland']], pawnee_pH_da)\n",
    "comanche_elev_da = clip_and_reproj_match(elev_da, select_grassland_gdf.loc[['Comanche National Grassland']], comanche_pH_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope and Aspect\n",
    "def get_slope_and_aspect(elevation_da):\n",
    "    \"\"\"\n",
    "    This function returns the slope and aspect for an elevation data\n",
    "    array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elevation_da: xarray.DataArray\n",
    "        A data array containing elevation values. Must be in \n",
    "        projected coordinate system with units of meters.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    slope_da: xarray.DataArray\n",
    "        A data array containing the slope values for the input raster\n",
    "    aspect_da: xarray.DataArray\n",
    "        A data array containing the aspect values for the input raster\n",
    "    \"\"\"\n",
    "    slope_da = slope(elevation_da)\n",
    "    aspect_da = aspect(elevation_da)\n",
    "    return slope_da, aspect_da\n",
    "\n",
    "# Get slope and aspect for Pawnee and Comanche\n",
    "comanche_slope_da, comanche_aspect_da = get_slope_and_aspect(comanche_elev_da)\n",
    "pawnee_slope_da, pawnee_aspect_da = get_slope_and_aspect(pawnee_elev_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A MACA2 file for this scenario is already saved in the directory. Skipping download.\n",
      "A MACA2 file for this scenario is already saved in the directory. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "def download_maca2_data(data_directory, model, scenario, variable_abb, st_year, end_year):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_directory: path\n",
    "        The path to the data directory where the MACA2 data will be \n",
    "        stored\n",
    "\n",
    "    model: string\n",
    "        Represents the selected MACA2 model that data will be downloaded \n",
    "        for. Acceptable values are: 'bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "        'BNU-ESM', 'CanESM2', 'CCSM4', 'CNRM-CM5', 'CSIRO-Mk3-6-0',\n",
    "        'GFDL-ESM2G', 'GFDL-ESM2M', 'HadGEM2-CC365', 'HadGEM2-ES365',\n",
    "        'inmcm4', 'IPSL-CM5A-MR', 'IPSL-CM5A-LR', 'IPSL-CM5B-LR','MIROC5',\n",
    "        'MIROC-ESM', 'MIROC-ESM-CHEM','MRI-CGCM3', 'NorESM1-M'.\n",
    "\n",
    "    scenario: string\n",
    "        Represents the climate scenario that data will be downloaded for.\n",
    "        Must be 'rcp45', 'rcp85', or 'historical'.\n",
    "\n",
    "    variable_abb: string\n",
    "        The abbreviation for the climate variable that data will be \n",
    "        downloaded for. Acceptable values are: tasmax', 'tasmin', \n",
    "        'rhsmax', 'rhsmin', 'pr', 'rsds', 'uas', 'vas', 'huss'.\n",
    "\n",
    "    st_year: integer\n",
    "        A four-digit integer representing the start year for the data \n",
    "        download. Must be between 2006 and 2099 for rcp45 and rcp85, or \n",
    "        between 1950 and 2005 for historical scenarios.\n",
    "\n",
    "    end_year: integer\n",
    "        A four-digit integer representing the end year for the data \n",
    "        download. Must be between 2006 and 2099 for rcp45 and rcp85, or \n",
    "        between 1950 and 2005 for historical scenarios.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    clim_da: xarray.Dataset\n",
    "        Returns a dataset containing the downloaded MACA2 data\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if model parameter is valid\n",
    "    model_lst = ['bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "        'BNU-ESM', 'CanESM2', 'CCSM4', 'CNRM-CM5', 'CSIRO-Mk3-6-0',\n",
    "        'GFDL-ESM2G', 'GFDL-ESM2M', 'HadGEM2-CC365', 'HadGEM2-ES365',\n",
    "        'inmcm4', 'IPSL-CM5A-MR', 'IPSL-CM5A-LR', 'IPSL-CM5B-LR','MIROC5',\n",
    "        'MIROC-ESM', 'MIROC-ESM-CHEM','MRI-CGCM3', 'NorESM1-M']\n",
    "    \n",
    "    if model not in model_lst:\n",
    "        raise ValueError(\"The listed model {0} is not valid.\"\n",
    "                         \"Check input\".format(model)\n",
    "                         )\n",
    "\n",
    "    # Define long variable names for MACA2 data\n",
    "    variables_long_list = ['precipitation', 'air_temperature', \n",
    "                      'air_temperature', 'relative_humidity',\n",
    "                      'relative_humidity', \n",
    "                      'surface_downwelling_shortwave_flux_in_air',\n",
    "                      'eastward_wind', \n",
    "                      'northward_wind',\n",
    "                      'specific_humidity'\n",
    "    ]\n",
    "\n",
    "    # Define abbreviated variable names for MACA2 data\n",
    "    variables_abb_lst = ['pr', 'tasmax', 'tasmin', 'rhsmin', 'rhsmax', \n",
    "                      'rsds', 'uas', 'vas', 'huss']\n",
    "    \n",
    "    if variable_abb not in variables_abb_lst:\n",
    "        raise ValueError(\"The listed variable abbreviation {0} is not \"\n",
    "                        \"valid. Check value\".format(variable_abb)\n",
    "                         )\n",
    "\n",
    "    # Create dictionary to get variable long name\n",
    "    variables_dict = {variables_abb_lst[i]: variables_long_list[i] \n",
    "           for i in range(len(variables_long_list))}\n",
    "\n",
    "    # Create template for MACA url path\n",
    "    template_url = (\"http://thredds.northwestknowledge.net:8080\"\\\n",
    "                \"/thredds/ncss/agg_macav2metdata_{0}_{1}_r\"\\\n",
    "                \"{2}i1p1_{3}_{4}_CONUS_monthly.nc\"\\\n",
    "                \"?var={5}\"\\\n",
    "                \"&disableLLSubset=on\"\n",
    "                \"&disableProjSubset=on\"\n",
    "                \"&horizStride=1&time_start={6}-01-15T00%3A00%3A00Z\"\n",
    "                \"&time_end={7}-12-15T00%3A00%3A00Z\"\n",
    "                \"&timeStride=1\"\n",
    "                \"&accept=netcdf\"\n",
    "    )\n",
    "\n",
    "    # Define whether url value is r6i1p1 or r1i1p1\n",
    "    if model == \"CCSM4\":\n",
    "        value = 6\n",
    "    else:\n",
    "        value = 1\n",
    "    \n",
    "    # Define year range for scenario\n",
    "    if scenario == \"historical\":\n",
    "        year_range = \"1950_2005\"\n",
    "    else:\n",
    "        year_range = \"2006_2099\"\n",
    "    \n",
    "    # Create url for download\n",
    "    url = template_url.format(variable_abb,\n",
    "                              model,\n",
    "                              value,\n",
    "                              scenario,\n",
    "                              year_range,\n",
    "                              variables_dict.get(variable_abb),\n",
    "                              st_year,\n",
    "                              end_year\n",
    "                              )\n",
    "\n",
    "    # Make request to url\n",
    "    maca_response = requests.get(url)\n",
    "\n",
    "    # Create template for MACA2 file name\n",
    "    template_filename = (\"{0}_{1}_{2}_{3}to{4}.nc\"\n",
    "    )\n",
    "\n",
    "    # Generate file name for saving\n",
    "    file_path = os.path.join(data_directory, \n",
    "                             template_filename.format(model,\n",
    "                                                      scenario,\n",
    "                                                      variable_abb,\n",
    "                                                      st_year,\n",
    "                                                      end_year\n",
    "                                                      )\n",
    "    )\n",
    "    \n",
    "    # If this MACA2 data does not yet exist in directory, download\n",
    "    if not os.path.exists(file_path):\n",
    "        # Save data\n",
    "        with open(file_path, 'wb') as maca_file:\n",
    "            maca_file.write(maca_response.content)\n",
    "        print(\"Downloading data\")\n",
    "\n",
    "    # Otherwise skip download\n",
    "    else:\n",
    "        print(\"A MACA2 file for this scenario is already saved in the \"\n",
    "              \"directory. Skipping download.\")\n",
    "\n",
    "    # Open the dataset and return\n",
    "    clim_dataset = xr.open_dataset(file_path)\n",
    "    return clim_dataset\n",
    "\n",
    "CCSM4_rcp45_da = download_maca2_data(\n",
    "    data_dir, \"CCSM4\", \"rcp45\", \"pr\", 2050, 2050)\n",
    "    \n",
    "CCSM4_rcp85_da = download_maca2_data(\n",
    "    data_dir, \"CCSM4\", \"rcp85\", \"pr\", 2050, 2050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign coords & set spatial dimensions\n",
    "def maca2_assign_coords(xr_dataset):\n",
    "    \"\"\"\n",
    "    Modifies longitude coordinates for a dataset to convert from 0-360\n",
    "    to -180 to 180. Also convers the data to a data_array and sets\n",
    "    the spatial dimensions and coordinate reference system.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    xr_dataset: xarray.DataSet\n",
    "        A dataset for which coordinates need to be modified from 0 to\n",
    "        360, to -180 to 180\n",
    "    \n",
    "    Returns\n",
    "    out_da: xarray.DataArray\n",
    "        A data array for which the longitude coordinates have been\n",
    "        converted to -180 to 180\n",
    "    \"\"\"\n",
    "    # Get data variable name from xr_dataset\n",
    "    var_name = list(xr_dataset.keys())[0]\n",
    "    # Assign coordinates\n",
    "    xr_dataset = xr_dataset.assign_coords(lon =  xr_dataset.lon - 360, inplace=True)\n",
    "    # Select data variable\n",
    "    out_da = xr_dataset[var_name]\n",
    "    # Change crs for data array\n",
    "    out_da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    # Set spatial dimensions for data array\n",
    "    out_da.rio.set_spatial_dims('lon','lat',inplace=True)\n",
    "    return out_da\n",
    "\n",
    "CCSM4_rcp45_da = maca2_assign_coords(CCSM4_rcp45_da)\n",
    "CCSM4_rcp85_da = maca2_assign_coords(CCSM4_rcp85_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip and Reproject Match the Precipitation Data for Scenarios in Both Sites\n",
    "comanche_CCSM4_rcp45_da = clip_and_reproj_match(CCSM4_rcp45_da, \n",
    "                                                select_grassland_gdf.loc[['Comanche National Grassland']],\n",
    "                                                comanche_pH_da)\n",
    "\n",
    "comanche_CCSM4_rcp85_da = clip_and_reproj_match(CCSM4_rcp85_da, \n",
    "                                                select_grassland_gdf.loc[['Comanche National Grassland']],\n",
    "                                                comanche_pH_da)\n",
    "\n",
    "pawnee_CCSM4_rcp45_da = clip_and_reproj_match(CCSM4_rcp45_da, \n",
    "                                                select_grassland_gdf.loc[['Pawnee National Grassland']],\n",
    "                                                pawnee_pH_da)\n",
    "\n",
    "pawnee_CCSM4_rcp85_da = clip_and_reproj_match(CCSM4_rcp85_da, \n",
    "                                                select_grassland_gdf.loc[['Pawnee National Grassland']],\n",
    "                                                pawnee_pH_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/workspaces/\")\n",
    "\n",
    "# Create Pawnee RCP 4.5 Model\n",
    "pawnee_rcp45_model = (((pawnee_pH_da < 8) * \n",
    "                (pawnee_pH_da > 4.8) * \n",
    "                (pawnee_CCSM4_rcp45_da.mean('time') < 45) * \n",
    "                (pawnee_CCSM4_rcp45_da.mean('time') > 11) *\n",
    "                (pawnee_elev_da < 6500) *\n",
    "                (pawnee_aspect_da > 90)\n",
    "                ).hvplot(rasterize=True) *\n",
    "                select_grassland_utm_gdf\n",
    "                .loc[['Pawnee National Grassland']]\n",
    "                .hvplot(line_color='red', color=None)).opts(\n",
    "                    xaxis=None,\n",
    "                    yaxis=None,\n",
    "                    title = (\"Pawnee Grassland Suitable\"\n",
    "                             \"Habitat (RCP 4.5 Scenario)\")\n",
    "                )\n",
    "\n",
    "hvplot.save(pawnee_rcp45_model, 'pawnee_rcp45_model.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pawnee RCP 4.5 Model\n",
    "comanche_rcp45_model = (((comanche_pH_da < 8) * \n",
    "                (comanche_pH_da > 4.8) * \n",
    "                (comanche_CCSM4_rcp45_da.mean('time') < 45) * \n",
    "                (comanche_CCSM4_rcp45_da.mean('time') > 11) *\n",
    "                (comanche_elev_da < 6500) *\n",
    "                (comanche_aspect_da > 90)\n",
    "                ).hvplot(rasterize=True) *\n",
    "                select_grassland_utm_gdf\n",
    "                .loc[['Comanche National Grassland']]\n",
    "                .hvplot(line_color='red', color=None)).opts(\n",
    "                    xaxis=None,\n",
    "                    yaxis=None,\n",
    "                    title = (\"Comanche Grassland Suitable\"\n",
    "                             \"Habitat (RCP 4.5 Scenario)\")\n",
    "                )\n",
    "\n",
    "hvplot.save(comanche_rcp45_model, 'comanche_rcp45_model.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to codespaces\n",
    "os.chdir(\"/workspaces/\")\n",
    "\n",
    "# Create & Save Pawnee pH Plot\n",
    "pawnee_ph_plt = (\n",
    "    pawnee_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\")\n",
    "hvplot.save(pawnee_ph_plt, 'pawnee_ph_plt.html')\n",
    "\n",
    "# Create & Save Comanche pH Plot\n",
    "comanche_ph_plt = (\n",
    "    comanche_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\")\n",
    "hvplot.save(comanche_ph_plt, 'comanche_ph_plt.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elevation plot for Pawnee\n",
    "pawnee_elev_plt = (\n",
    "    pawnee_elev_da.hvplot(cmap=\"YlOrBr\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='black', color=None)\n",
    "    ).opts(xaxis=None,\n",
    "           yaxis=None,\n",
    "           title = \"Elevation\")\n",
    "hvplot.save(pawnee_elev_plt, 'pawnee_elev_plt.html')\n",
    "\n",
    "# Create elevation plot for Comanche\n",
    "comanche_elev_plt = (\n",
    "    comanche_elev_da.hvplot(cmap=\"YlOrBr\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='black', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Elevation\")\n",
    "hvplot.save(comanche_elev_plt, 'comanche_elev_plt.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aspect plot for Pawnee\n",
    "pawnee_aspect_plt = (\n",
    "    pawnee_aspect_da.hvplot(cmap=\"gist_heat_r\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='black', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Aspect\")\n",
    "hvplot.save(pawnee_aspect_plt, 'pawnee_aspect_plt.html')\n",
    "\n",
    "# Create elevation plot for Comanche\n",
    "comanche_aspect_plt = (\n",
    "    comanche_aspect_da.hvplot(cmap=\"gist_heat_r\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='black', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Aspect\")\n",
    "hvplot.save(comanche_aspect_plt, 'comanche_aspect_plt.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RCP 4.5 plot for Pawnee\n",
    "pawnee_rcp45_plt = (\n",
    "    pawnee_CCSM4_rcp45_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='red', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 4.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(pawnee_rcp45_plt, 'pawnee_rcp45_plt.html')\n",
    "\n",
    "# Create RCP 4.5 plot for Pawnee\n",
    "pawnee_rcp85_plt = (\n",
    "    pawnee_CCSM4_rcp85_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='red', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 8.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(pawnee_rcp85_plt, 'pawnee_rcp85_plt.html')\n",
    "\n",
    "# Create RCP 4.5 plot for Comanche\n",
    "comanche_rcp45_plt = (\n",
    "   comanche_CCSM4_rcp45_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='red', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 4.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(comanche_rcp45_plt, 'comanche_rcp45_plt.html')\n",
    "\n",
    "# Create RCP 8.5 plot for Comanche\n",
    "comanche_rcp85_plt = (\n",
    "   comanche_CCSM4_rcp85_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='red', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 8.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(comanche_rcp85_plt, 'comanche_rcp85_plt.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhv\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mhv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomanche_rcp85_plt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomanche_rcp85_plt.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/holoviews/util/__init__.py:807\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, filename, fmt, backend, resources, toolbar, title, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m formats[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m supported:\n\u001b[1;32m    806\u001b[0m         filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(formats[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/holoviews/plotting/renderer.py:598\u001b[0m, in \u001b[0;36mRenderer.save\u001b[0;34m(self_or_cls, obj, basename, fmt, key, info, options, resources, title, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     plot\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39msave(basename, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, resources\u001b[38;5;241m=\u001b[39mresources, title\u001b[38;5;241m=\u001b[39mtitle)\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[43mself_or_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rendered \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    600\u001b[0m (data, info) \u001b[38;5;241m=\u001b[39m rendered\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/holoviews/plotting/renderer.py:199\u001b[0m, in \u001b[0;36mRenderer.__call__\u001b[0;34m(self, obj, fmt, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_html(plot), info\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_figure_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_post_render_hooks(data, obj, fmt)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, info\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/holoviews/plotting/bokeh/renderer.py:125\u001b[0m, in \u001b[0;36mBokehRenderer._figure_data\u001b[0;34m(self, plot, fmt, doc, as_script, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbokeh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_screenshot_as_png\n\u001b[0;32m--> 125\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mget_screenshot_as_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwebdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     imgByteArr \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[1;32m    127\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(imgByteArr, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPNG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bokeh/io/export.py:271\u001b[0m, in \u001b[0;36mget_screenshot_as_png\u001b[0;34m(obj, driver, timeout, resources, width, height, scale_factor, state)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected the web driver to have a device pixel ratio greater than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_factor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    269\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWas given a web driver with a device pixel ratio of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_pixel_ratio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     web_driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m web_driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[1;32m    273\u001b[0m web_driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bokeh/io/webdriver.py:174\u001b[0m, in \u001b[0;36m_WebdriverState.get\u001b[0;34m(self, scale_factor)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scale_factor_less_than_web_driver_device_pixel_ratio(\n\u001b[1;32m    172\u001b[0m         scale_factor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bokeh/io/webdriver.py:178\u001b[0m, in \u001b[0;36m_WebdriverState.create\u001b[0;34m(self, kind, scale_factor)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kind: DriverKind \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, scale_factor: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WebDriver:\n\u001b[0;32m--> 178\u001b[0m     driver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drivers\u001b[38;5;241m.\u001b[39madd(driver)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m driver\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bokeh/io/webdriver.py:196\u001b[0m, in \u001b[0;36m_WebdriverState._create\u001b[0;34m(self, kind, scale_factor)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirefox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m driver\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither firefox and geckodriver nor a variant of chromium browser and \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    197\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromedriver are available on system PATH. You can install the former \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    198\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge firefox geckodriver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m driver_kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromium\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_chromium_webdriver(scale_factor\u001b[38;5;241m=\u001b[39mscale_factor)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'."
     ]
    }
   ],
   "source": [
    "import holoviews as hv\n",
    "hv.save(comanche_rcp85_plt, 'comanche_rcp85_plt.png', fmt='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
