{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import io\n",
    "import math \n",
    "import os\n",
    "# import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.appeears as etapp\n",
    "import earthpy.earthexplorer as etee\n",
    "import geopandas as gpd\n",
    "import hvplot.xarray  \n",
    "import hvplot.pandas\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "import requests\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "# from shapely.geometry import box\n",
    "from xrspatial import aspect\n",
    "from xrspatial import slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME, 'final_project')\n",
    "if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "# Make data directory the working directory\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Define utm zone\n",
    "utm = 32613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading shapefile...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from: https://medium.com/@loldja/reading-shapefile-zips-from-a-url-in-python-3-93ea8d727856\n",
    "# Create directory\n",
    "grassland_url = ('https://data.fs.usda.gov/geodata/edw/'\n",
    "                 'edw_resources/shp/S_USA.NationalGrassland.zip'\n",
    ")\n",
    "print('Downloading shapefile...')\n",
    "\n",
    "# Request data from url\n",
    "grassland_request = requests.get(grassland_url)\n",
    "grassland_zip = zipfile.ZipFile(io.BytesIO(grassland_request.content))\n",
    "\n",
    "# Extract files from zip and save to directory\n",
    "grassland_zip.extractall(\n",
    "    path=os.path.join(data_dir, 'national-grassland')\n",
    "    )\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile\n",
    "grassland_gdf = gpd.read_file(os.path.join(\n",
    "    data_dir, 'national-grassland', 'S_USA.NationalGrassland.shp')\n",
    "    )\n",
    "\n",
    "# Get selected grasslands\n",
    "select_grassland_gdf = (\n",
    "    grassland_gdf\n",
    "    .set_index('GRASSLANDN')\n",
    "    .loc[['Comanche National Grassland', 'Pawnee National Grassland']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Comanche National Grassland :\n",
      "mean_ph_lat3637_lon-105-104.tif does not exist. Downloading file\n",
      "mean_ph_lat3637_lon-104-103.tif does not exist. Downloading file\n",
      "mean_ph_lat3637_lon-103-102.tif does not exist. Downloading file\n",
      "mean_ph_lat3738_lon-105-104.tif does not exist. Downloading file\n",
      "mean_ph_lat3738_lon-104-103.tif does not exist. Downloading file\n",
      "mean_ph_lat3738_lon-103-102.tif does not exist. Downloading file\n",
      "Soil data is being merged.\n",
      "Merged soil file created.\n",
      "\n",
      " Pawnee National Grassland :\n",
      "mean_ph_lat4041_lon-105-104.tif does not exist. Downloading file\n",
      "mean_ph_lat4041_lon-104-103.tif does not exist. Downloading file\n",
      "mean_ph_lat4142_lon-105-104.tif does not exist. Downloading file\n",
      "mean_ph_lat4142_lon-104-103.tif does not exist. Downloading file\n",
      "Soil data is being merged.\n",
      "Merged soil file created.\n"
     ]
    }
   ],
   "source": [
    "def get_polaris_data(data_directory, input_gdf, index_col_name):\n",
    "    \"\"\"\n",
    "    This function downloads Polaris soil data for the extent of each \n",
    "    row in a geodataframe and creates a merged data array for each. \n",
    "    Downloaded data is saved in individual folders for each row. Merged \n",
    "    data arrays for each row are saved in \"Merged_files\" subfolder.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_directory : path\n",
    "        The path to the data directory. A sub-directory will be created\n",
    "        within this directory for the soil data downloads. \n",
    "\n",
    "    input_gdf: geopandas.GeoDataFrame\n",
    "        A geodataframe that contains the areas of interest. Polaris soil\n",
    "        data will be downloaded according to the bounds of each row in \n",
    "        the dataframe. \n",
    "    \n",
    "    index_col_name: string\n",
    "        A string containing the name of the geoDataFrame column that\n",
    "        should be used as the index. This index will be used to name\n",
    "        output files.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    output_lst: list of data arrays\n",
    "        Returns a list of data arrays representing the merged Polaris\n",
    "        tif data for each row in the input geodataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Set index to specified index column\n",
    "    input_gdf = input_gdf.reset_index().set_index(index_col_name)\n",
    "\n",
    "    # Create dataframe of bounds of each gdf row\n",
    "    bound_pd = pd.concat([input_gdf.bounds], axis=1)\n",
    "\n",
    "    file_list = []\n",
    "    \n",
    "    # Loop through each row in the boundary dataframe\n",
    "    for ind in bound_pd.index:\n",
    "        print(\"\\n\", ind, \":\")\n",
    "        # Define and round min and max longitude and latitudes\n",
    "        min_lon = math.floor(bound_pd['minx'][ind])\n",
    "        max_lon = math.ceil(bound_pd['maxx'][ind])\n",
    "        min_lat = math.floor(bound_pd['miny'][ind])\n",
    "        max_lat = math.ceil(bound_pd['maxy'][ind])\n",
    "        # Define range\n",
    "        lat_range = range(min_lat,max_lat)\n",
    "        lon_range = range(min_lon,max_lon)\n",
    "\n",
    "        # Create template for polaris url path\n",
    "        polaris_template_url = 'http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/' \\\n",
    "                    '{0}/{1}/{2}/lat{3}{4}_lon{5}{6}.tif'\n",
    "        # Create template for file names\n",
    "        polaris_template_name = 'mean_ph_lat{0}{1}_lon{2}{3}.tif'\n",
    "\n",
    "        # Create sub-directory for soil data\n",
    "        soil_dir = os.path.join(data_directory, \"soil_data\")\n",
    "        if not os.path.exists(soil_dir):\n",
    "            os.makedirs(soil_dir)\n",
    "\n",
    "        # Create sub-folders for each row's data\n",
    "        soil_row_dir = os.path.join(soil_dir, str(ind).replace(\" \", \"_\"))\n",
    "        if not os.path.exists(soil_row_dir):\n",
    "            os.makedirs(soil_row_dir)\n",
    "        \n",
    "        # Create sub-folder for merged data arrays\n",
    "        soil_merged_dir = os.path.join(soil_dir, \"Merged_tifs\")\n",
    "        if not os.path.exists(soil_merged_dir):\n",
    "            os.makedirs(soil_merged_dir)\n",
    "        \n",
    "        # For each latitude and longitude in the extent, download file\n",
    "        for lat in lat_range:\n",
    "            for lon in lon_range:\n",
    "                # Define url for each data file in extent\n",
    "                url = polaris_template_url.format('ph',\n",
    "                                        'mean',\n",
    "                                        '60_100',\n",
    "                                        str(lat),\n",
    "                                        str(lat+1),\n",
    "                                        str(lon),\n",
    "                                        str(lon+1))\n",
    "                # Define file name for each data file in extent\n",
    "                file_name = polaris_template_name.format(str(lat),\n",
    "                                        str(lat+1),\n",
    "                                        str(lon),\n",
    "                                        str(lon+1))\n",
    "                # Check if tif file is in directory. Download if not.\n",
    "                file_name_path = os.path.join(soil_row_dir, file_name)\n",
    "                if not os.path.exists(file_name_path): \n",
    "                    print(file_name, \"does not exist. Downloading file\")\n",
    "                    r = requests.get(url, allow_redirects=True)\n",
    "                    open(file_name_path, 'wb').write(r.content)\n",
    "                else:\n",
    "                    print(file_name, \"is already downloaded\")\n",
    "\n",
    "        # Merge arrays if the merged file does not exist\n",
    "        merge_template_name = '{0}_merged_da.tif'\n",
    "        merge_da_name = merge_template_name.format(str(ind).replace(\" \", \"_\"), \".tif\")\n",
    "        if not os.path.exists(os.path.join(soil_merged_dir, merge_da_name)): \n",
    "            print(\"Soil data is being merged.\")\n",
    "            tif_paths = glob(os.path.join(soil_row_dir, '*.tif'))\n",
    "            das = [rxr.open_rasterio(tif, masked=True) for tif in tif_paths]\n",
    "            merged_da = rxrmerge.merge_arrays(das)\n",
    "            merged_da.rio.to_raster(\n",
    "                os.path.join(soil_merged_dir, merge_da_name)\n",
    "                )\n",
    "            print(\"Merged soil file created.\")\n",
    "        else:\n",
    "            print(\"A merged soil data array already exists.\")\n",
    "            merged_da = rxr.open_rasterio(\n",
    "                os.path.join(soil_merged_dir, merge_da_name), masked=True\n",
    "                )\n",
    "        \n",
    "        # Add file to list of tif files to return\n",
    "        file_list.append(os.path.join(soil_merged_dir, merge_da_name))\n",
    "        \n",
    "    # Return files\n",
    "    output_lst = [rxr.open_rasterio(tif, masked=True).squeeze() for tif in file_list]\n",
    "    return output_lst\n",
    "\n",
    "comanche_pH_da, pawnee_pH_da = get_polaris_data(data_dir, select_grassland_gdf, \"GRASSLANDN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change projection of grassland data\n",
    "select_grassland_utm_gdf = select_grassland_gdf.to_crs(utm)\n",
    "\n",
    "# Clip pH files to bounds\n",
    "comanche_pH_da = (comanche_pH_da\n",
    "                  .rio.reproject(utm)\n",
    "                  .rio.clip_box(\n",
    "                      *select_grassland_utm_gdf\n",
    "                      .loc[['Comanche National Grassland']]\n",
    "                      .total_bounds)\n",
    ")\n",
    "pawnee_pH_da = (pawnee_pH_da\n",
    "                  .rio.reproject(utm)\n",
    "                  .rio.clip_box(\n",
    "                      *select_grassland_utm_gdf\n",
    "                      .loc[['Pawnee National Grassland']]\n",
    "                      .total_bounds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pawnee_ph_plt = (\n",
    "    pawnee_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\"\n",
    ")\n",
    "\n",
    "comanche_ph_plt = (\n",
    "    comanche_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change crs of selected grasslands\n",
    "select_grassland_gdf = select_grassland_gdf.to_crs(4326)\n",
    "\n",
    "# Download AppEEARS SRTM DEM data for full extent\n",
    "elevation_downloader = etapp.AppeearsDownloader(\n",
    "    download_key=\"SRTM_DEM\",\n",
    "    ea_dir=data_dir,\n",
    "    product=\"SRTMGL1_NC.003\",\n",
    "    layer=\"SRTMGL1_DEM\",\n",
    "    start_date=\"02-11\",\n",
    "    end_date=\"02-21\",\n",
    "    recurring=True,\n",
    "    year_range=[2000,2000],\n",
    "    polygon=select_grassland_gdf,\n",
    ")\n",
    "\n",
    "# Download files if the download directory does not exist\n",
    "if not os.path.exists(elevation_downloader.data_dir):\n",
    "    elevation_downloader.download_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read elevation data.\n",
    "for tif in glob(os.path.join(data_dir, 'SRTM_DEM',\n",
    "                'SRTMGL1_NC*',\n",
    "                '*.tif')):\n",
    "    elev_da = rxr.open_rasterio(tif, masked=True).squeeze()\n",
    "    elev_da.name = 'Elevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_and_reproj_match(in_da, clip_gdf, match_da):\n",
    "    \"\"\"\n",
    "    This function clips a data array to a specificed extent and \n",
    "    harmonizes the array to match another data array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_da: xarray.DataArray\n",
    "        Represents the data array that is to be clipped and reprojected\n",
    "\n",
    "    clip_gdf: geopandas.GeoDataFrame\n",
    "        The geodataframe to which the data input area should be clipped\n",
    "\n",
    "    match_da: xarray.DataArray\n",
    "        The data array for which the input data array should be \n",
    "        reprojected to match the resolution, projection, and region\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    clip_da: xarray.DataArray\n",
    "        A clipped and harmonized version of the input data array\n",
    "    \"\"\"\n",
    "    # Clip to extent of input and reproject match to specified array\n",
    "    clip_da = (in_da\n",
    "                  .rio.clip_box(*clip_gdf.to_crs(in_da.rio.crs)\n",
    "                                .total_bounds)\n",
    "                  .rio.reproject_match(match_da))\n",
    "    \n",
    "    return clip_da\n",
    "\n",
    "# Run function for Pawnee and Comanche\n",
    "pawnee_elev_da = clip_and_reproj_match(elev_da, select_grassland_gdf.loc[['Pawnee National Grassland']], pawnee_pH_da)\n",
    "comanche_elev_da = clip_and_reproj_match(elev_da, select_grassland_gdf.loc[['Comanche National Grassland']], pawnee_pH_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope and Aspect\n",
    "def get_slope_and_aspect(elevation_da):\n",
    "    \"\"\"\n",
    "    This function returns the slope and aspect for an elevation data\n",
    "    array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elevation_da: xarray.DataArray\n",
    "        A data array containing elevation values. Must be in \n",
    "        projected coordinate system with units of meters.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    slope_da: xarray.DataArray\n",
    "        A data array containing the slope values for the input raster\n",
    "    aspect_da: xarray.DataArray\n",
    "        A data array containing the aspect values for the input raster\n",
    "    \"\"\"\n",
    "    slope_da = slope(elevation_da)\n",
    "    aspect_da = aspect(elevation_da)\n",
    "    return slope_da, aspect_da\n",
    "\n",
    "# Get slope and aspect for Pawnee and Comanche\n",
    "comanche_slope_da, comanche_aspect_da = get_slope_and_aspect(comanche_elev_da)\n",
    "pawnee_slope_da, pawnee_aspect_da = get_slope_and_aspect(pawnee_elev_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data\n",
      "Downloading data\n"
     ]
    }
   ],
   "source": [
    "def download_maca2_data(data_directory, model, scenario, variable_abb, st_year, end_year):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_directory: path\n",
    "        The path to the data directory where the MACA2 data will be \n",
    "        stored\n",
    "\n",
    "    model: string\n",
    "        Represents the selected MACA2 model that data will be downloaded \n",
    "        for. Acceptable values are: 'bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "        'BNU-ESM', 'CanESM2', 'CCSM4', 'CNRM-CM5', 'CSIRO-Mk3-6-0',\n",
    "        'GFDL-ESM2G', 'GFDL-ESM2M', 'HadGEM2-CC365', 'HadGEM2-ES365',\n",
    "        'inmcm4', 'IPSL-CM5A-MR', 'IPSL-CM5A-LR', 'IPSL-CM5B-LR','MIROC5',\n",
    "        'MIROC-ESM', 'MIROC-ESM-CHEM','MRI-CGCM3', 'NorESM1-M'.\n",
    "\n",
    "    scenario: string\n",
    "        Represents the climate scenario that data will be downloaded for.\n",
    "        Must be 'rcp45', 'rcp85', or 'historical'.\n",
    "\n",
    "    variable_abb: string\n",
    "        The abbreviation for the climate variable that data will be \n",
    "        downloaded for. Acceptable values are: tasmax', 'tasmin', \n",
    "        'rhsmax', 'rhsmin', 'pr', 'rsds', 'uas', 'vas', 'huss'.\n",
    "\n",
    "    st_year: integer\n",
    "        A four-digit integer representing the start year for the data \n",
    "        download. Must be between 2006 and 2099 for rcp45 and rcp85, or \n",
    "        between 1950 and 2005 for historical scenarios.\n",
    "\n",
    "    end_year: integer\n",
    "        A four-digit integer representing the end year for the data \n",
    "        download. Must be between 2006 and 2099 for rcp45 and rcp85, or \n",
    "        between 1950 and 2005 for historical scenarios.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    clim_da: xarray.Dataset\n",
    "        Returns a dataset containing the downloaded MACA2 data\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if model parameter is valid\n",
    "    model_lst = ['bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "        'BNU-ESM', 'CanESM2', 'CCSM4', 'CNRM-CM5', 'CSIRO-Mk3-6-0',\n",
    "        'GFDL-ESM2G', 'GFDL-ESM2M', 'HadGEM2-CC365', 'HadGEM2-ES365',\n",
    "        'inmcm4', 'IPSL-CM5A-MR', 'IPSL-CM5A-LR', 'IPSL-CM5B-LR','MIROC5',\n",
    "        'MIROC-ESM', 'MIROC-ESM-CHEM','MRI-CGCM3', 'NorESM1-M']\n",
    "    \n",
    "    if model not in model_lst:\n",
    "        raise ValueError(\"The listed model {0} is not valid.\"\n",
    "                         \"Check input\".format(model)\n",
    "                         )\n",
    "\n",
    "    # Define long variable names for MACA2 data\n",
    "    variables_long_list = ['precipitation', 'air_temperature', \n",
    "                      'air_temperature', 'relative_humidity',\n",
    "                      'relative_humidity', \n",
    "                      'surface_downwelling_shortwave_flux_in_air',\n",
    "                      'eastward_wind', \n",
    "                      'northward_wind',\n",
    "                      'specific_humidity'\n",
    "    ]\n",
    "\n",
    "    # Define abbreviated variable names for MACA2 data\n",
    "    variables_abb_lst = ['pr', 'tasmax', 'tasmin', 'rhsmin', 'rhsmax', \n",
    "                      'rsds', 'uas', 'vas', 'huss']\n",
    "    \n",
    "    if variable_abb not in variables_abb_lst:\n",
    "        raise ValueError(\"The listed variable abbreviation {0} is not \"\n",
    "                        \"valid. Check value\".format(variable_abb)\n",
    "                         )\n",
    "\n",
    "    # Create dictionary to get variable long name\n",
    "    variables_dict = {variables_abb_lst[i]: variables_long_list[i] \n",
    "           for i in range(len(variables_long_list))}\n",
    "\n",
    "    # Create template for MACA url path\n",
    "    template_url = (\"http://thredds.northwestknowledge.net:8080\"\\\n",
    "                \"/thredds/ncss/agg_macav2metdata_{0}_{1}_r\"\\\n",
    "                \"{2}i1p1_{3}_{4}_CONUS_monthly.nc\"\\\n",
    "                \"?var={5}\"\\\n",
    "                \"&disableLLSubset=on\"\n",
    "                \"&disableProjSubset=on\"\n",
    "                \"&horizStride=1&time_start={6}-01-15T00%3A00%3A00Z\"\n",
    "                \"&time_end={7}-12-15T00%3A00%3A00Z\"\n",
    "                \"&timeStride=1\"\n",
    "                \"&accept=netcdf\"\n",
    "    )\n",
    "\n",
    "    # Define whether url value is r6i1p1 or r1i1p1\n",
    "    if model == \"CCSM4\":\n",
    "        value = 6\n",
    "    else:\n",
    "        value = 1\n",
    "    \n",
    "    # Define year range for scenario\n",
    "    if scenario == \"historical\":\n",
    "        year_range = \"1950_2005\"\n",
    "    else:\n",
    "        year_range = \"2006_2099\"\n",
    "    \n",
    "    # Create url for download\n",
    "    url = template_url.format(variable_abb,\n",
    "                              model,\n",
    "                              value,\n",
    "                              scenario,\n",
    "                              year_range,\n",
    "                              variables_dict.get(variable_abb),\n",
    "                              st_year,\n",
    "                              end_year\n",
    "                              )\n",
    "\n",
    "    # Make request to url\n",
    "    maca_response = requests.get(url)\n",
    "\n",
    "    # Create template for MACA2 file name\n",
    "    template_filename = (\"{0}_{1}_{2}_{3}to{4}.nc\"\n",
    "    )\n",
    "\n",
    "    # Generate file name for saving\n",
    "    file_path = os.path.join(data_directory, \n",
    "                             template_filename.format(model,\n",
    "                                                      scenario,\n",
    "                                                      variable_abb,\n",
    "                                                      st_year,\n",
    "                                                      end_year\n",
    "                                                      )\n",
    "    )\n",
    "    \n",
    "    # If this MACA2 data does not yet exist in directory, download\n",
    "    if not os.path.exists(file_path):\n",
    "        # Save data\n",
    "        with open(file_path, 'wb') as maca_file:\n",
    "            maca_file.write(maca_response.content)\n",
    "        print(\"Downloading data\")\n",
    "\n",
    "    # Otherwise skip download\n",
    "    else:\n",
    "        print(\"A MACA2 file for this scenario is already saved in the \"\n",
    "              \"directory. Skipping download.\")\n",
    "\n",
    "    # Open the dataset and return\n",
    "    clim_dataset = xr.open_dataset(file_path)\n",
    "    return clim_dataset\n",
    "\n",
    "CCSM4_rcp45_da = download_maca2_data(data_dir, \"CCSM4\", \"rcp45\", \"pr\", 2040, 2040)\n",
    "    \n",
    "CCSM4_rcp85_da = download_maca2_data(data_dir, \"CCSM4\", \"rcp85\", \"pr\", 2040, 2040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign coords & set spatial dimensions\n",
    "def maca2_assign_coords(xr_dataset):\n",
    "    \"\"\"\n",
    "    Modifies longitude coordinates for a dataset to convert from 0-360\n",
    "    to -180 to 180. Also convers the data to a data_array and sets\n",
    "    the spatial dimensions and coordinate reference system.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    xr_dataset: xarray.DataSet\n",
    "        A dataset for which coordinates need to be modified from 0 to\n",
    "        360, to -180 to 180\n",
    "    \n",
    "    Returns\n",
    "    out_da: xarray.DataArray\n",
    "        A data array for which the longitude coordinates have been\n",
    "        converted to -180 to 180\n",
    "    \"\"\"\n",
    "    # Get data variable name from xr_dataset\n",
    "    var_name = list(xr_dataset.keys())[0]\n",
    "    # Assign coordinates\n",
    "    xr_dataset = xr_dataset.assign_coords(lon =  xr_dataset.lon - 360, inplace=True)\n",
    "    # Select data variable\n",
    "    out_da = xr_dataset[var_name]\n",
    "    # Change crs for data array\n",
    "    out_da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    # Set spatial dimensions for data array\n",
    "    out_da.rio.set_spatial_dims('lon','lat',inplace=True)\n",
    "    return out_da\n",
    "\n",
    "CCSM4_rcp45_da = maca2_assign_coords(CCSM4_rcp45_da)\n",
    "CCSM4_rcp85_da = maca2_assign_coords(CCSM4_rcp85_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Clip and Reproject Match the Precipitation Data for Scenarios in Both Sites\n",
    "comanche_CCSM4_rcp45_da = clip_and_reproj_match(CCSM4_rcp45_da, \n",
    "                                                select_grassland_gdf.loc[['Comanche National Grassland']],\n",
    "                                                comanche_pH_da)\n",
    "\n",
    "comanche_CCSM4_rcp85_da = clip_and_reproj_match(CCSM4_rcp85_da, \n",
    "                                                select_grassland_gdf.loc[['Comanche National Grassland']],\n",
    "                                                comanche_pH_da)\n",
    "\n",
    "pawnee_CCSM4_rcp45_da = clip_and_reproj_match(CCSM4_rcp45_da, \n",
    "                                                select_grassland_gdf.loc[['Pawnee National Grassland']],\n",
    "                                                pawnee_pH_da)\n",
    "\n",
    "pawnee_CCSM4_rcp85_da = clip_and_reproj_match(CCSM4_rcp85_da, \n",
    "                                                select_grassland_gdf.loc[['Pawnee National Grassland']],\n",
    "                                                pawnee_pH_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pawnee_rcp85 = (((pawnee_pH_da < 8) * \n",
    "                (pawnee_pH_da > 4.8) * \n",
    "                (pawnee_CCSM4_rcp85_da.mean('time') < 45) * \n",
    "                (pawnee_CCSM4_rcp85_da.mean('time') > 11) *\n",
    "                (pawnee_elev_da < 6500) *\n",
    "                (pawnee_aspect_da > 90)\n",
    "                ).hvplot(rasterize=True) *\n",
    "                select_grassland_gdf\n",
    "                .loc[['Pawnee National Grassland']]\n",
    "                .hvplot(line_color='white', color=None)\n",
    ")\n",
    "\n",
    "os.chdir(\"/workspaces/\")\n",
    "hvplot.save(pawnee_rcp85, 'pawnee_rcp85.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to codespaces\n",
    "os.chdir(\"/workspaces/\")\n",
    "\n",
    "# Create & Save Pawnee pH Plot\n",
    "pawnee_ph_plt = (\n",
    "    pawnee_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\")\n",
    "hvplot.save(pawnee_ph_plt, 'pawnee_ph_plt.html')\n",
    "\n",
    "# Create & Save Comanche pH Plot\n",
    "comanche_ph_plt = (\n",
    "    comanche_pH_da.hvplot(cmap=\"bgy\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Soil pH at 60-100cm depth\")\n",
    "hvplot.save(comanche_ph_plt, 'comanche_ph_plt.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elevation plot for Pawnee\n",
    "pawnee_elev_plt = (\n",
    "    pawnee_elev_da.hvplot(cmap=\"YlOrBr\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    "    ).opts(xaxis=None,\n",
    "           yaxis=None,\n",
    "           title = \"Elevation\")\n",
    "hvplot.save(pawnee_elev_plt, 'pawnee_elev_plt.html')\n",
    "\n",
    "# Create elevation plot for Comanche\n",
    "comanche_elev_plt = (\n",
    "    comanche_elev_da.hvplot(cmap=\"YlOrBr\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Elevation\")\n",
    "hvplot.save(comanche_elev_plt, 'comanche_elev_plt.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aspect plot for Pawnee\n",
    "pawnee_aspect_plt = (\n",
    "    pawnee_aspect_da.hvplot(cmap=\"gist_heat_r\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Aspect\")\n",
    "hvplot.save(pawnee_aspect_plt, 'pawnee_aspect_plt.html')\n",
    "\n",
    "# Create elevation plot for Comanche\n",
    "comanche_aspect_plt = (\n",
    "    comanche_aspect_da.hvplot(cmap=\"gist_heat_r\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"Aspect\")\n",
    "hvplot.save(comanche_aspect_da, 'comanche_aspect_da.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RCP 4.5 plot for Pawnee\n",
    "pawnee_rcp45_plt = (\n",
    "    pawnee_CCSM4_rcp45_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 4.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(pawnee_rcp45_plt, 'pawnee_rcp45_plt.html')\n",
    "\n",
    "# Create RCP 4.5 plot for Pawnee\n",
    "pawnee_rcp85_plt = (\n",
    "    pawnee_CCSM4_rcp85_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Pawnee National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 8.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(pawnee_rcp85_plt, 'pawnee_rcp85_plt.html')\n",
    "\n",
    "# Create RCP 4.5 plot for Comanche\n",
    "comanche_rcp45_plt = (\n",
    "   comanche_CCSM4_rcp45_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 4.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(comanche_rcp45_plt, 'comanche_rcp45_plt.html')\n",
    "\n",
    "# Create RCP 8.5 plot for Comanche\n",
    "comanche_rcp85_plt = (\n",
    "   comanche_CCSM4_rcp85_da.mean(\"time\").hvplot(cmap=\"blues\") \n",
    "    * select_grassland_utm_gdf\n",
    "    .loc[['Comanche National Grassland']]\n",
    "    .hvplot(line_width=1, line_color='white', color=None)\n",
    ").opts(xaxis=None,\n",
    "    yaxis=None,\n",
    "    title = \"RCP 8.5 Mean Precipitation in 2050\")\n",
    "hvplot.save(comanche_rcp85_plt, 'comanche_rcp85_plt.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
